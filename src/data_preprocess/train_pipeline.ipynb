{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Training Pipeline for Data Preprocessing\n\nComplete 5-stage data preprocessing pipeline for model training.\n\n**Pipeline Stages:**\n1. Data Cleaning: Raw CSV → Cleaned CSV\n2. Feature Engineering: Cleaned CSV → Clustered CSV (with BERT encoding)\n3. Fraud Matching: Clustered CSV → Categorized by Member\n4. Feature Encoding: Processed CSV → Final Encoded Dataset\n5. Vulnerability Scanning: Security testing on final data (Optional)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import and Configuration\n",
    "\n",
    "**New Approach**: All paths and parameters are configured in `config/pipeline_config.py`\n",
    "- No more scattered path definitions\n",
    "- Easy to switch between train/pred modes\n",
    "- Centralized parameter management"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:51:06.917754Z",
     "start_time": "2025-12-06T23:51:06.908242Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import centralized configuration\n",
    "from config.pipeline_config import get_train_config\n",
    "\n",
    "# Get training configuration\n",
    "config = get_train_config()\n",
    "config.print_config()\n",
    "\n",
    "# Create all necessary directories\n",
    "print(\"\\nCreating directories...\")\n",
    "config.create_directories()\n",
    "\n",
    "print(\"\\n✓ Configuration loaded successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ClearShield Pipeline Configuration - Mode: TRAIN\n",
      "======================================================================\n",
      "\n",
      "Project Root: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield\n",
      "\n",
      "Data Paths:\n",
      "  raw                 : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "  cleaned             : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "  clustered           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "  by_member           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "  final               : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "  by_member_temp      : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "  by_member_matched   : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/matched\n",
      "  by_member_unmatched : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/unmatched\n",
      "  by_member_no_fraud  : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/no_fraud\n",
      "  final_matched       : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/matched\n",
      "  final_unmatched     : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/unmatched\n",
      "  final_no_fraud      : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/no_fraud\n",
      "  model_dir           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/src/data_preprocess/02_feature_engineering/02b_description_encoding\n",
      "  cluster_model       : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/src/data_preprocess/02_feature_engineering/02b_description_encoding/global_cluster_model.pkl\n",
      "  tokenize_config     : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/config/tokenize_dict.json\n",
      "\n",
      "Feature Engineering Parameters:\n",
      "  model_name          : prajjwal1/bert-tiny\n",
      "  text_column         : Transaction Description\n",
      "  batch_size          : 64\n",
      "  max_length          : 64\n",
      "  pca_dim             : 20\n",
      "  min_k               : 10\n",
      "  max_k               : 60\n",
      "  k_step              : 10\n",
      "  sample_size         : 10000\n",
      "  cluster_batch_size  : 4096\n",
      "  random_state        : 42\n",
      "\n",
      "Fraud Matching Parameters:\n",
      "  chunksize           : 50000\n",
      "  min_history_length  : 10\n",
      "======================================================================\n",
      "\n",
      "Creating directories...\n",
      "Created 9 directories:\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/matched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/unmatched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/no_fraud\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/matched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/unmatched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/no_fraud\n",
      "\n",
      "✓ Configuration loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processing Modules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:51:12.419367Z",
     "start_time": "2025-12-06T23:51:12.400541Z"
    }
   },
   "source": "# Import data cleaning module\nsys.path.insert(0, os.path.abspath('./01_data_cleaning'))\nspec = importlib.util.spec_from_file_location(\n    \"data_cleaning\",\n    \"./01_data_cleaning/01_data_cleaning.py\"\n)\ndc = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(dc)\n\n# Import feature engineering module\nspec = importlib.util.spec_from_file_location(\n    \"feature_engineering\",\n    \"02_feature_engineering/02_feature_engineering.py\"\n)\nfe = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(fe)\n\n# Import fraud relabeling module\nspec = importlib.util.spec_from_file_location(\n    \"fraud_relabeling\",\n    \"03_fraud_relabeling/03_fraud_relabeling.py\"\n)\nfr = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(fr)\n\n# Import encoding module\nspec = importlib.util.spec_from_file_location(\n    \"encoding\",\n    \"04_encoding/04_encoding.py\"\n)\nenc = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(enc)\n\n# Import vulnerability scanner module\nsys.path.insert(0, os.path.abspath('./05_security'))\nspec = importlib.util.spec_from_file_location(\n    \"vuln_scanner\",\n    \"./05_security/vuln_scanner.py\"\n)\nvuln_scanner = importlib.util.module_from_spec(spec)\nspec.loader.exec_module(vuln_scanner)\nrun_vulnerability_scan = vuln_scanner.run_vulnerability_scan\n\nprint(\"✓ All modules loaded successfully!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Modules Using Centralized Config"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:51:49.765736Z",
     "start_time": "2025-12-06T23:51:49.760106Z"
    }
   },
   "source": "# Configure data cleaning\ndc.ENABLE_RENAMING = True\ndc.RAW_DIR = str(config.get_path('raw'))\ndc.CLEANED_DIR = str(config.get_path('cleaned'))\n\n# Configure feature engineering\nfe.PROCESSED_DIR = str(config.get_path('cleaned'))\nfe.MODEL_NAME = config.feature_engineering['model_name']\nfe.TEXT_COLUMN = config.feature_engineering['text_column']\nfe.BATCH_SIZE = config.feature_engineering['batch_size']\nfe.MAX_LENGTH = config.feature_engineering['max_length']\nfe.PCA_DIM = config.feature_engineering['pca_dim']\nfe.MIN_K = config.feature_engineering['min_k']\nfe.MAX_K = config.feature_engineering['max_k']\nfe.K_STEP = config.feature_engineering['k_step']\nfe.SAMPLE_SIZE = config.feature_engineering['sample_size']\nfe.CLUSTER_BATCH_SIZE = config.feature_engineering['cluster_batch_size']\nfe.RANDOM_STATE = config.feature_engineering['random_state']\n\n# Configure fraud relabeling\nfr.INPUT_DIR = str(config.get_path('clustered'))\nfr.OUTPUT_MEMBER_DIR = str(config.get_path('by_member_temp'))\nfr.OUTPUT_PROCESSED_DIR = str(config.get_path('by_member'))\nfr.CHUNKSIZE = config.fraud_matching['chunksize']\nfr.MIN_HISTORY_LENGTH = config.fraud_matching['min_history_length']\n\n# Configure encoding\nenc.PROCESSED_DIR = str(config.get_path('by_member'))\nenc.OUTPUT_DIR = str(config.get_path('final'))\nenc.CONFIG_PATH = str(config.get_path('tokenize_config'))\n\n# Configure vulnerability scanner\nVULN_CONFIG = {\n    'final_data_path': str(config.get_path('final')),\n    'data_file_pattern': '*.csv',\n    'data_sample_size': 1000,\n    'export_path': str(config.PROJECT_ROOT / 'vulnerability_scan_results.json'),\n    'verbose': True\n}\n\nprint(\"✓ All modules configured successfully!\")\nprint(f\"\\nPipeline will process:\")\nprint(f\"  Raw data:     {dc.RAW_DIR}\")\nprint(f\"  Final output: {enc.OUTPUT_DIR}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules configured successfully!\n",
      "\n",
      "Pipeline will process:\n",
      "  Raw data:     /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "  Final output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Cleaning\n",
    "\n",
    "This cell performs the following preprocessing tasks:\n",
    "1. Standardize headers (e.g., \"AccountID\" → \"Account ID\")\n",
    "2. Fix comma issues (remove extra commas in field values)\n",
    "3. Clean Amount field (remove $ and commas, convert to numeric)\n",
    "4. Fill missing values (Amount→0, others→\"Unknown\", \"null\"→empty)\n",
    "5. Rename files based on date range (MM-DD-YYYY_to_MM-DD-YYYY.csv)\n",
    "\n",
    "**Data Flow**: `data/train/raw/` → `data/train/cleaned/`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:52:06.572463Z",
     "start_time": "2025-12-06T23:51:56.450646Z"
    }
   },
   "source": [
    "dc.main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "Cleaned: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "\n",
      "Found 1 CSV files in /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "\n",
      "CSV Files List ⬇️\n",
      "  1. part01.csv (2.99 MB)\n",
      "\n",
      "============================================================\n",
      "Processing Files...\n",
      "============================================================\n",
      "\n",
      "[1/1] part01.csv... Amount:27351, Missing:1277, →09-01-2024_to_09-19-2024.csv\n",
      "\n",
      "============================================================\n",
      "Processing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Feature Engineering: Description Encoding and Clustering\n",
    "\n",
    "This stage performs advanced feature engineering on transaction descriptions:\n",
    "\n",
    "1. **BERT Encoding**: Use BERT-tiny model to encode \"Transaction Description\" text into embeddings\n",
    "2. **Dimensionality Reduction**: Apply PCA to reduce embedding dimensions (default: 20D)\n",
    "3. **Automatic Clustering**: Find optimal cluster count (k) via heuristic search and cluster with MiniBatchKMeans\n",
    "4. **Add Cluster ID**: Append `cluster_id` column to each CSV file\n",
    "\n",
    "**Data Flow**: `data/train/cleaned/` → `data/train/clustered_out/`\n",
    "\n",
    "**Note**: This step requires GPU/CPU compute and may take significant time depending on data size."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:52:32.112272Z",
     "start_time": "2025-12-06T23:52:27.867849Z"
    }
   },
   "source": [
    "outputs = fe.main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 2: DESCRIPTION ENCODING AND CLUSTERING\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "Model: prajjwal1/bert-tiny\n",
      "Text Column: Transaction Description\n",
      "PCA Dimensions: 20\n",
      "Cluster Range: 10-60 (step 10)\n",
      "\n",
      "[Scan] Found 1 CSV file(s) in /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Saved 1 clustered file(s) to /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "\n",
      "============================================================\n",
      "STAGE 2 COMPLETE\n",
      "============================================================\n",
      "Processed 1 files\n",
      "Output location: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Fraud Matching and Re-labeling\n",
    "\n",
    "This cell performs fraud detection in two stages:\n",
    "\n",
    "1. **Reorganize by Member**: Group all transactions by Member ID into individual files (temp directory)\n",
    "2. **Match Fraud Adjustments**: Find and mark original fraudulent transactions for each refund record (≥10 transactions)\n",
    "   - Match by amount and date (extract from description or 30-day range)\n",
    "   - Prevent duplicate matching\n",
    "   - Categorize as matched/unmatched/no_fraud\n",
    "   - Automatically delete temp directory after processing\n",
    "\n",
    "**Data Flow**: `data/train/clustered_out/` → `data/train/by_member/[matched|unmatched|no_fraud]/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3-1: Reorganize transactions by member\n",
    "\n",
    "**Data Flow**: `data/train/clustered_out/` → `data/train/by_member/temp/` (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:53:07.451036Z",
     "start_time": "2025-12-06T23:53:05.126728Z"
    }
   },
   "source": [
    "num_members = fr.run_stage1()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 1: DATA REORGANIZATION\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "\n",
      "Found 1 files\n",
      "Processing 1/1: 09-01-2024_to_09-19-2024.csv\n",
      "Modified 1116 member files this run\n",
      "Sorting modified files...\n",
      "  Sorted 1000/1116 files\n",
      "\n",
      "1116 member files created\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check member transaction distribution"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T20:37:48.514884Z",
     "start_time": "2025-11-20T20:37:47.643184Z"
    }
   },
   "source": [
    "from glob import glob\n",
    "\n",
    "# Get member files and count transactions\n",
    "member_files = glob(os.path.join(fr.OUTPUT_MEMBER_DIR, 'member_*.csv'))\n",
    "counts = [len(pd.read_csv(f)) for f in member_files]\n",
    "\n",
    "# Calculate statistics\n",
    "threshold = fr.MIN_HISTORY_LENGTH\n",
    "total_count = len(counts)\n",
    "above_n = sum(1 for c in counts if c >= threshold)\n",
    "below_n = total_count - above_n\n",
    "above_ratio = (above_n / total_count) * 100\n",
    "below_ratio = (below_n / total_count) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Threshold set to: {threshold}\")\n",
    "print(f\"Records >= {threshold}: {above_n:,} ({above_ratio:.2f}%)\")\n",
    "print(f\"Records < {threshold}: {below_n:,} ({below_ratio:.2f}%)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set to: 10\n",
      "Records >= 10: 936 (62.82%)\n",
      "Records < 10: 554 (37.18%)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3-2: Fraud detection and matching\n",
    "\n",
    "Filter members with minimum history length (≥10 transactions), then match fraud adjustments to original transactions.\n",
    "\n",
    "**Data Flow**: `data/train/by_member/temp/` → `data/train/by_member/[matched|unmatched|no_fraud]/`\n",
    "\n",
    "**Note**: The temp directory will be automatically deleted after processing completes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:53:16.186335Z",
     "start_time": "2025-12-06T23:53:14.906922Z"
    }
   },
   "source": [
    "stats = fr.run_stage2(fr.MIN_HISTORY_LENGTH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 2: FRAUD DETECTION\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "Min History Length: 10\n",
      "\n",
      "Found 1116 member files\n",
      "Filtering: only processing members with >= 10 transactions\n",
      "  Processed 1000/1116 members\n",
      "Summary saved to: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/member_summary.csv\n",
      "\n",
      "Cleaned up temporary directory: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "\n",
      "Processing Summary:\n",
      "  Total Processed: 678\n",
      "  Skipped (< 10 txns): 438\n",
      "  No Fraud: 672\n",
      "  Matched: 4\n",
      "  Unmatched: 2\n",
      "\n",
      "============================================================\n",
      "COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Encoding\n",
    "\n",
    "This stage encodes categorical features and prepares the final dataset for model training:\n",
    "\n",
    "1. **Remove ID Columns**: Delete Account ID and Member ID\n",
    "2. **Encode Categorical Features**: Convert categorical columns to numeric using predefined dictionary\n",
    "   - Account Type, Action Type, Source Type, Product ID\n",
    "3. **Parse Time Features**: Convert Post Time to decimal hours\n",
    "4. **Convert Date Features**: Parse Post Date and Account Open Date\n",
    "5. **Clean Up**: Remove text columns (Transaction Description, Fraud Adjustment Indicator)\n",
    "\n",
    "**Data Flow**: `data/train/by_member/[matched|unmatched|no_fraud]/` → `data/train/final/[matched|unmatched|no_fraud]/`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:53:47.557551Z",
     "start_time": "2025-12-06T23:53:44.464992Z"
    }
   },
   "source": [
    "total_processed = enc.encode_features(enc.PROCESSED_DIR, enc.OUTPUT_DIR, enc.CONFIG_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Dir: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "Output Dir: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "Config Path: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/config/tokenize_dict.json\n",
      "\n",
      "Loaded encoding dictionary with 4 features\n",
      "\n",
      "matched: Found 4 files\n",
      "  matched: Encoded 4/4 files\n",
      "\n",
      "unmatched: Found 2 files\n",
      "  unmatched: Encoded 2/2 files\n",
      "\n",
      "no_fraud: Found 672 files\n",
      "  Processed 100/672 files\n",
      "  Processed 200/672 files\n",
      "  Processed 300/672 files\n",
      "  Processed 400/672 files\n",
      "  Processed 500/672 files\n",
      "  Processed 600/672 files\n",
      "  no_fraud: Encoded 672/672 files\n",
      "\n",
      "============================================================\n",
      "Encoding Complete!\n",
      "Total files found: 678\n",
      "Total files processed: 678\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 5. Vulnerability Scanning (Optional)\n\nRun security vulnerability tests on the final processed data to detect potential data quality issues, adversarial risks, and model vulnerabilities.\n\n**Tests include:**\n- Data quality validation\n- Statistical distribution checks\n- Adversarial robustness testing\n- Fairness and bias detection\n- Privacy leakage checks\n\n**Data Source**: `data/train/final/`",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Run vulnerability scan\nscan_results = run_vulnerability_scan(**VULN_CONFIG)\n\n# Display summary\nprint(f\"\\n{'='*60}\")\nprint(\"VULNERABILITY SCAN SUMMARY\")\nprint(f\"{'='*60}\")\nprint(f\"Total Tests: {scan_results['total_tests']}\")\nprint(f\"Passed: {scan_results['status_breakdown'].get('PASSED', 0)}\")\nprint(f\"Failed: {scan_results['status_breakdown'].get('FAILED', 0)}\")\nprint(f\"Warnings: {scan_results['status_breakdown'].get('WARNING', 0)}\")\nprint(f\"Skipped: {scan_results['status_breakdown'].get('SKIPPED', 0)}\")\nprint(f\"Total Vulnerabilities: {scan_results['total_vulnerabilities']}\")\nprint(f\"{'='*60}\")\n\nif scan_results['total_vulnerabilities'] > 0:\n    print(\"\\n⚠ Security vulnerabilities detected. Please review the detailed results.\")\n    print(f\"Results saved to: {VULN_CONFIG['export_path']}\")\nelse:\n    print(\"\\n✓ No critical vulnerabilities detected!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T23:54:53.465966Z",
     "start_time": "2025-12-06T23:54:52.915779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLEARSHIELD VULNERABILITY SCANNER\n",
      "======================================================================\n",
      "Data path: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "Sample size: 1000\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LOADING DATA FROM FINAL FOLDER\n",
      "======================================================================\n",
      "Loading data from: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "  ✓ Loaded 265 rows from matched/\n",
      "  ✓ Loaded 44 rows from unmatched/\n",
      "  ✓ Loaded 25419 rows from no_fraud/\n",
      "  ✓ Total rows loaded: 25728\n",
      "  ✓ Sampled to 1000 rows\n",
      "  ✓ Converted to tensor shape: torch.Size([100, 10, 8])\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Running vulnerability tests...\n",
      "\n",
      "======================================================================\n",
      "CLEARSHIELD FRAUD DETECTION - COMPREHENSIVE TEST SUITE\n",
      "======================================================================\n",
      "Start Time: 2025-12-06 15:54:53\n",
      "\n",
      "\n",
      "[1/5] Running Data Preprocessing Tests...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[2/5] Running Clustering Module Tests...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[3/5] Running Model Tests (Transformer Encoder)...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[4/5] Running Performance & Integration Tests...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[5/5] Running Security & Compliance Tests...\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "======================================================================\n",
      "TEST EXECUTION SUMMARY\n",
      "======================================================================\n",
      "Total Tests Run: 18\n",
      "Total Execution Time: 0.11s\n",
      "\n",
      "Test Results by Status:\n",
      "  PASSED: 8\n",
      "  FAILED: 6\n",
      "  SKIPPED: 4\n",
      "\n",
      "Total Security Vulnerabilities: 1\n",
      "Vulnerabilities by Severity:\n",
      "  CRITICAL: 1\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DETAILED RESULTS BY MODULE\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Data Preprocessing:\n",
      "  [SKIP] Missing Value Handling\n",
      "        None of the required columns ['transaction_id', 'user_id', 'amount', 'timestamp'] found in dataframe\n",
      "  [SKIP] Duplicate Detection\n",
      "        Key columns ['transaction_id'] not found in dataframe\n",
      "  [SKIP] Feature Extraction Validation\n",
      "        User ID column 'user_id' not found in dataframe\n",
      "  [SKIP] Fraud Flag Conversion\n",
      "        Fraud column 'is_fraud' not found in dataframe\n",
      "\n",
      "Clustering Module:\n",
      "  [PASS] K-Means Implementation\n",
      "        K-Means successfully created 5 clusters\n",
      "  [PASS] Optimal K Validation\n",
      "        Optimal K: 2 (silhouette: 0.938)\n",
      "  [PASS] Cluster Reproducibility\n",
      "        Clustering is reproducible across 5 runs\n",
      "  [PASS] Davies-Bouldin Index\n",
      "        Good cluster separation (DB Index: 0.565)\n",
      "\n",
      "Model (Transformer):\n",
      "  [PASS] Architecture Validation\n",
      "        Transformer architecture validated successfully\n",
      "  [FAIL] Sequence Input Formatting\n",
      "        Error: mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)\n",
      "\n",
      "Performance & Integration:\n",
      "  [FAIL] Inference Latency P99 (REQ-P1)\n",
      "        Error: mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)\n",
      "  [FAIL] Concurrent Load Testing\n",
      "        Error: mat1 and mat2 shapes cannot be multiplied (100000x8 and 20x64)\n",
      "  [PASS] Model Serialization\n",
      "        Model serialization/deserialization successful\n",
      "\n",
      "Security & Compliance:\n",
      "  [PASS] PII Compliance (REQ-F5)\n",
      "        No direct PII columns detected\n",
      "  [FAIL] Adversarial Robustness\n",
      "        Error: mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)\n",
      "  [FAIL] Input Validation\n",
      "        3/3 input validation tests failed\n",
      "        Details: {'test_cases': [('extreme_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)'), ('zero_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)'), ('negative_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)')], 'extreme_multiplier': 1000000.0}\n",
      "  [FAIL] Privacy Leakage Risk\n",
      "        Error: mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)\n",
      "  [PASS] Model Poisoning Indicators\n",
      "        No model poisoning indicators detected\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "SECURITY VULNERABILITIES\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. [CRITICAL] Input Validation Missing\n",
      "   Description: Model crashes or produces invalid outputs on edge case inputs\n",
      "   Recommendation: Add input validation, normalization, and error handling before model inference\n",
      "   Details: {'failed_tests': [('extreme_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)'), ('zero_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)'), ('negative_values', 'FAIL', 'mat1 and mat2 shapes cannot be multiplied (1000x8 and 20x64)')]}\n",
      "\n",
      "======================================================================\n",
      "END OF REPORT\n",
      "======================================================================\n",
      "\n",
      "Test results exported to: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/vulnerability_scan_results.json\n",
      "\n",
      "Results exported to: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/vulnerability_scan_results.json\n",
      "\n",
      "======================================================================\n",
      "VULNERABILITY SCAN COMPLETED\n",
      "======================================================================\n",
      "\n",
      "============================================================\n",
      "VULNERABILITY SCAN SUMMARY\n",
      "============================================================\n",
      "Total Tests: 18\n",
      "Passed: 8\n",
      "Failed: 6\n",
      "Warnings: 0\n",
      "Skipped: 4\n",
      "Total Vulnerabilities: 1\n",
      "============================================================\n",
      "\n",
      "⚠ Security vulnerabilities detected. Please review the detailed results.\n",
      "Results saved to: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/vulnerability_scan_results.json\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "## Pipeline Complete!\n",
    "\n",
    "The complete data preprocessing pipeline consists of 4 main stages + 1 optional security stage:\n",
    "\n",
    "1. **Data Cleaning**: Raw CSV → Cleaned CSV (`data/train/cleaned/`)\n",
    "2. **Feature Engineering**: Cleaned CSV → Clustered CSV (`data/train/clustered_out/`)\n",
    "3. **Fraud Matching**: Clustered CSV → Categorized by Member (`data/train/by_member/[matched|unmatched|no_fraud]/`)\n",
    "4. **Feature Encoding**: Processed CSV → Final Encoded Dataset (`data/train/final/[matched|unmatched|no_fraud]/`)\n",
    "5. **Vulnerability Scanning** (Optional): Security testing on final data\n",
    "\n",
    "**Final Output**: `data/train/final/[matched|unmatched|no_fraud]/member_*.csv`\n",
    "\n",
    "These final encoded files are ready for model training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
