{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline for Data Preprocessing\n",
    "\n",
    "Complete 4-stage data preprocessing pipeline for model training.\n",
    "\n",
    "**Pipeline Stages:**\n",
    "1. Data Cleaning: Raw CSV → Cleaned CSV\n",
    "2. Feature Engineering: Cleaned CSV → Clustered CSV (with BERT encoding)\n",
    "3. Fraud Matching: Clustered CSV → Categorized by Member\n",
    "4. Feature Encoding: Processed CSV → Final Encoded Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import and Configuration\n",
    "\n",
    "**New Approach**: All paths and parameters are configured in `config/pipeline_config.py`\n",
    "- No more scattered path definitions\n",
    "- Easy to switch between train/pred modes\n",
    "- Centralized parameter management"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:25.014977Z",
     "start_time": "2025-11-20T05:40:24.788231Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parents[1]\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Import centralized configuration\n",
    "from config.pipeline_config import get_train_config\n",
    "\n",
    "# Get training configuration\n",
    "config = get_train_config()\n",
    "config.print_config()\n",
    "\n",
    "# Create all necessary directories\n",
    "print(\"\\nCreating directories...\")\n",
    "config.create_directories()\n",
    "\n",
    "print(\"\\n✓ Configuration loaded successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ClearShield Pipeline Configuration - Mode: TRAIN\n",
      "======================================================================\n",
      "\n",
      "Project Root: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield\n",
      "\n",
      "Data Paths:\n",
      "  raw                 : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "  cleaned             : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "  clustered           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "  by_member           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "  final               : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "  by_member_temp      : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "  by_member_matched   : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/matched\n",
      "  by_member_unmatched : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/unmatched\n",
      "  by_member_no_fraud  : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/no_fraud\n",
      "  final_matched       : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/matched\n",
      "  final_unmatched     : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/unmatched\n",
      "  final_no_fraud      : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/no_fraud\n",
      "  model_dir           : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/src/data_preprocess/02_feature_engineering/02b_description_encoding\n",
      "  cluster_model       : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/src/data_preprocess/02_feature_engineering/02b_description_encoding/global_cluster_model.pkl\n",
      "  tokenize_config     : /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/config/tokenize_dict.json\n",
      "\n",
      "Feature Engineering Parameters:\n",
      "  model_name          : prajjwal1/bert-tiny\n",
      "  text_column         : Transaction Description\n",
      "  batch_size          : 64\n",
      "  max_length          : 64\n",
      "  pca_dim             : 20\n",
      "  min_k               : 10\n",
      "  max_k               : 60\n",
      "  k_step              : 10\n",
      "  sample_size         : 10000\n",
      "  cluster_batch_size  : 4096\n",
      "  random_state        : 42\n",
      "\n",
      "Fraud Matching Parameters:\n",
      "  chunksize           : 50000\n",
      "  min_history_length  : 10\n",
      "======================================================================\n",
      "\n",
      "Creating directories...\n",
      "Created 4 directories:\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/matched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/unmatched\n",
      "  ✓ /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final/no_fraud\n",
      "\n",
      "✓ Configuration loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Processing Modules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:28.839450Z",
     "start_time": "2025-11-20T05:40:28.831421Z"
    }
   },
   "source": [
    "# Import data cleaning module\n",
    "sys.path.insert(0, os.path.abspath('./01_data_cleaning'))\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"data_cleaning\",\n",
    "    \"./01_data_cleaning/01_data_cleaning.py\"\n",
    ")\n",
    "dc = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(dc)\n",
    "\n",
    "# Import feature engineering module\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"feature_engineering\",\n",
    "    \"02_feature_engineering/02_feature_engineering.py\"\n",
    ")\n",
    "fe = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(fe)\n",
    "\n",
    "# Import fraud relabeling module\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"fraud_relabeling\",\n",
    "    \"03_fraud_relabeling/03_fraud_relabeling.py\"\n",
    ")\n",
    "fr = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(fr)\n",
    "\n",
    "# Import encoding module\n",
    "spec = importlib.util.spec_from_file_location(\n",
    "    \"encoding\",\n",
    "    \"04_encoding/04_encoding.py\"\n",
    ")\n",
    "enc = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(enc)\n",
    "\n",
    "print(\"✓ All modules loaded successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Modules Using Centralized Config"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:31.120633Z",
     "start_time": "2025-11-20T05:40:31.112475Z"
    }
   },
   "source": [
    "# Configure data cleaning\n",
    "dc.ENABLE_RENAMING = True\n",
    "dc.RAW_DIR = str(config.get_path('raw'))\n",
    "dc.CLEANED_DIR = str(config.get_path('cleaned'))\n",
    "\n",
    "# Configure feature engineering\n",
    "fe.PROCESSED_DIR = str(config.get_path('cleaned'))\n",
    "fe.MODEL_NAME = config.feature_engineering['model_name']\n",
    "fe.TEXT_COLUMN = config.feature_engineering['text_column']\n",
    "fe.BATCH_SIZE = config.feature_engineering['batch_size']\n",
    "fe.MAX_LENGTH = config.feature_engineering['max_length']\n",
    "fe.PCA_DIM = config.feature_engineering['pca_dim']\n",
    "fe.MIN_K = config.feature_engineering['min_k']\n",
    "fe.MAX_K = config.feature_engineering['max_k']\n",
    "fe.K_STEP = config.feature_engineering['k_step']\n",
    "fe.SAMPLE_SIZE = config.feature_engineering['sample_size']\n",
    "fe.CLUSTER_BATCH_SIZE = config.feature_engineering['cluster_batch_size']\n",
    "fe.RANDOM_STATE = config.feature_engineering['random_state']\n",
    "\n",
    "# Configure fraud relabeling\n",
    "fr.INPUT_DIR = str(config.get_path('clustered'))\n",
    "fr.OUTPUT_MEMBER_DIR = str(config.get_path('by_member_temp'))\n",
    "fr.OUTPUT_PROCESSED_DIR = str(config.get_path('by_member'))\n",
    "fr.CHUNKSIZE = config.fraud_matching['chunksize']\n",
    "fr.MIN_HISTORY_LENGTH = config.fraud_matching['min_history_length']\n",
    "\n",
    "# Configure encoding\n",
    "enc.PROCESSED_DIR = str(config.get_path('by_member'))\n",
    "enc.OUTPUT_DIR = str(config.get_path('final'))\n",
    "enc.CONFIG_PATH = str(config.get_path('tokenize_config'))\n",
    "\n",
    "print(\"✓ All modules configured successfully!\")\n",
    "print(f\"\\nPipeline will process:\")\n",
    "print(f\"  Raw data:     {dc.RAW_DIR}\")\n",
    "print(f\"  Final output: {enc.OUTPUT_DIR}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules configured successfully!\n",
      "\n",
      "Pipeline will process:\n",
      "  Raw data:     /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "  Final output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Data Cleaning\n",
    "\n",
    "This cell performs the following preprocessing tasks:\n",
    "1. Standardize headers (e.g., \"AccountID\" → \"Account ID\")\n",
    "2. Fix comma issues (remove extra commas in field values)\n",
    "3. Clean Amount field (remove $ and commas, convert to numeric)\n",
    "4. Fill missing values (Amount→0, others→\"Unknown\", \"null\"→empty)\n",
    "5. Rename files based on date range (MM-DD-YYYY_to_MM-DD-YYYY.csv)\n",
    "\n",
    "**Data Flow**: `data/train/raw/` → `data/train/cleaned/`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:54.714491Z",
     "start_time": "2025-11-20T05:40:54.493313Z"
    }
   },
   "source": [
    "dc.main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "Cleaned: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "\n",
      "Found 1 CSV files in /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/raw\n",
      "\n",
      "CSV Files List ⬇️\n",
      "  1. test.csv (0.06 MB)\n",
      "\n",
      "============================================================\n",
      "Processing Files...\n",
      "============================================================\n",
      "\n",
      "[1/1] test.csv... Missing:31, →01-01-2025_to_01-01-2025.csv\n",
      "\n",
      "============================================================\n",
      "Processing Complete!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Feature Engineering: Description Encoding and Clustering\n",
    "\n",
    "This stage performs advanced feature engineering on transaction descriptions:\n",
    "\n",
    "1. **BERT Encoding**: Use BERT-tiny model to encode \"Transaction Description\" text into embeddings\n",
    "2. **Dimensionality Reduction**: Apply PCA to reduce embedding dimensions (default: 20D)\n",
    "3. **Automatic Clustering**: Find optimal cluster count (k) via heuristic search and cluster with MiniBatchKMeans\n",
    "4. **Add Cluster ID**: Append `cluster_id` column to each CSV file\n",
    "\n",
    "**Data Flow**: `data/train/cleaned/` → `data/train/clustered_out/`\n",
    "\n",
    "**Note**: This step requires GPU/CPU compute and may take significant time depending on data size."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:58.270582Z",
     "start_time": "2025-11-20T05:40:56.655583Z"
    }
   },
   "source": [
    "outputs = fe.main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 2: DESCRIPTION ENCODING AND CLUSTERING\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "Model: prajjwal1/bert-tiny\n",
      "Text Column: Transaction Description\n",
      "PCA Dimensions: 20\n",
      "Cluster Range: 10-60 (step 10)\n",
      "\n",
      "[Scan] Found 1 CSV file(s) in /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Done] Saved 1 clustered file(s) to /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "\n",
      "============================================================\n",
      "STAGE 2 COMPLETE\n",
      "============================================================\n",
      "Processed 1 files\n",
      "Output location: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Fraud Matching and Re-labeling\n",
    "\n",
    "This cell performs fraud detection in two stages:\n",
    "\n",
    "1. **Reorganize by Member**: Group all transactions by Member ID into individual files (temp directory)\n",
    "2. **Match Fraud Adjustments**: Find and mark original fraudulent transactions for each refund record (≥10 transactions)\n",
    "   - Match by amount and date (extract from description or 30-day range)\n",
    "   - Prevent duplicate matching\n",
    "   - Categorize as matched/unmatched/no_fraud\n",
    "   - Automatically delete temp directory after processing\n",
    "\n",
    "**Data Flow**: `data/train/clustered_out/` → `data/train/by_member/[matched|unmatched|no_fraud]/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3-1: Reorganize transactions by member\n",
    "\n",
    "**Data Flow**: `data/train/clustered_out/` → `data/train/by_member/temp/` (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:40:59.105977Z",
     "start_time": "2025-11-20T05:40:58.568510Z"
    }
   },
   "source": [
    "num_members = fr.run_stage1()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 1: DATA REORGANIZATION\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/clustered_out\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "\n",
      "Found 1 files\n",
      "Processing 1/1: 01-01-2025_to_01-01-2025.csv\n",
      "Modified 300 member files this run\n",
      "Sorting modified files...\n",
      "\n",
      "300 member files created\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check member transaction distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Get member files and count transactions\n",
    "member_files = glob(os.path.join(fr.OUTPUT_MEMBER_DIR, 'member_*.csv'))\n",
    "counts = [len(pd.read_csv(f)) for f in member_files]\n",
    "\n",
    "# Calculate statistics\n",
    "threshold = fr.MIN_HISTORY_LENGTH\n",
    "total_count = len(counts)\n",
    "above_n = sum(1 for c in counts if c >= threshold)\n",
    "below_n = total_count - above_n\n",
    "above_ratio = (above_n / total_count) * 100\n",
    "below_ratio = (below_n / total_count) * 100\n",
    "\n",
    "# Print results\n",
    "print(f\"Threshold set to: {threshold}\")\n",
    "print(f\"Records >= {threshold}: {above_n:,} ({above_ratio:.2f}%)\")\n",
    "print(f\"Records < {threshold}: {below_n:,} ({below_ratio:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3-2: Fraud detection and matching\n",
    "\n",
    "Filter members with minimum history length (≥10 transactions), then match fraud adjustments to original transactions.\n",
    "\n",
    "**Data Flow**: `data/train/by_member/temp/` → `data/train/by_member/[matched|unmatched|no_fraud]/`\n",
    "\n",
    "**Note**: The temp directory will be automatically deleted after processing completes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:41:08.251115Z",
     "start_time": "2025-11-20T05:41:08.050105Z"
    }
   },
   "source": [
    "stats = fr.run_stage2(fr.MIN_HISTORY_LENGTH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STAGE 2: FRAUD DETECTION\n",
      "============================================================\n",
      "Input: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "Output: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "Min History Length: 10\n",
      "\n",
      "Found 300 member files\n",
      "Filtering: only processing members with >= 10 transactions\n",
      "Summary saved to: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/member_summary.csv\n",
      "\n",
      "Cleaned up temporary directory: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member/temp\n",
      "\n",
      "Processing Summary:\n",
      "  Total Processed: 1\n",
      "  Skipped (< 10 txns): 299\n",
      "  No Fraud: 1\n",
      "  Matched: 0\n",
      "  Unmatched: 0\n",
      "\n",
      "============================================================\n",
      "COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feature Encoding\n",
    "\n",
    "This stage encodes categorical features and prepares the final dataset for model training:\n",
    "\n",
    "1. **Remove ID Columns**: Delete Account ID and Member ID\n",
    "2. **Encode Categorical Features**: Convert categorical columns to numeric using predefined dictionary\n",
    "   - Account Type, Action Type, Source Type, Product ID\n",
    "3. **Parse Time Features**: Convert Post Time to decimal hours\n",
    "4. **Convert Date Features**: Parse Post Date and Account Open Date\n",
    "5. **Clean Up**: Remove text columns (Transaction Description, Fraud Adjustment Indicator)\n",
    "\n",
    "**Data Flow**: `data/train/by_member/[matched|unmatched|no_fraud]/` → `data/train/final/[matched|unmatched|no_fraud]/`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:41:10.872816Z",
     "start_time": "2025-11-20T05:41:10.858368Z"
    }
   },
   "source": [
    "total_processed = enc.encode_features(enc.PROCESSED_DIR, enc.OUTPUT_DIR, enc.CONFIG_PATH)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENCODING\n",
      "============================================================\n",
      "Input Dir: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/by_member\n",
      "Output Dir: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/data/train/final\n",
      "Config Path: /Users/wwy/Documents/CMU/25-Fall/Practicum/Clearshield/config/tokenize_dict.json\n",
      "\n",
      "Loaded encoding dictionary with 4 features\n",
      "\n",
      "matched: No member files found\n",
      "\n",
      "unmatched: No member files found\n",
      "\n",
      "no_fraud: Found 1 files\n",
      "  no_fraud: Encoded 1/1 files\n",
      "\n",
      "============================================================\n",
      "Encoding Complete!\n",
      "Total files found: 1\n",
      "Total files processed: 1\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pipeline Complete!\n",
    "\n",
    "The complete data preprocessing pipeline consists of 4 stages:\n",
    "\n",
    "1. **Data Cleaning**: Raw CSV → Cleaned CSV (`data/train/cleaned/`)\n",
    "2. **Feature Engineering**: Cleaned CSV → Clustered CSV (`data/train/clustered_out/`)\n",
    "3. **Fraud Matching**: Clustered CSV → Categorized by Member (`data/train/by_member/[matched|unmatched|no_fraud]/`)\n",
    "4. **Feature Encoding**: Processed CSV → Final Encoded Dataset (`data/train/final/[matched|unmatched|no_fraud]/`)\n",
    "\n",
    "**Final Output**: `data/train/final/[matched|unmatched|no_fraud]/member_*.csv`\n",
    "\n",
    "These final encoded files are ready for model training!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
