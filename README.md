# ğŸ” Clearshield

A machine learning system for detecting fraudulent transactions using traditional ML algorithms and LSTM neural networks.

## ğŸ“‹ Overview

This fraud detection system combines traditional machine learning with deep learning approaches to identify fraudulent transactions. The system features a hybrid architecture that leverages both statistical features and sequential patterns.

## ğŸ“ Project Structure

```
ClearShield/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original datasets
â”‚   â”œâ”€â”€ cleaned/                 # Cleaned datasets (Step 1)
â”‚   â”œâ”€â”€ clustered_out/           # Clustered datasets (Step 2)
â”‚   â”œâ”€â”€ by_member/               # Member-grouped datasets (Step 3 intermediate)
â”‚   â”œâ”€â”€ processed/               # Fraud-matched datasets (Step 3)
â”‚   â”‚   â”œâ”€â”€ matched/             # Members with matched fraud
â”‚   â”‚   â”œâ”€â”€ unmatched/           # Members with unmatched fraud
â”‚   â”‚   â””â”€â”€ no_fraud/            # Members without fraud
â”‚   â”œâ”€â”€ final/                   # Final encoded datasets (Step 4)
â”‚   â”‚   â”œâ”€â”€ matched/             # Ready for model training
â”‚   â”‚   â”œâ”€â”€ unmatched/
â”‚   â”‚   â””â”€â”€ no_fraud/
â”‚   â””â”€â”€ external/                # External data sources (optional)
â”‚
â”œâ”€â”€ docs/                        # Documentation files
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for analysis
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocess/
â”‚   â”‚   â”œâ”€â”€ 01_data_cleaning/        # Step 1: Data cleaning scripts
â”‚   â”‚   â”œâ”€â”€ 02_feature_engineering/  # Step 2: Feature engineering
â”‚   â”‚   â”‚   â”œâ”€â”€ 02a_transaction_type_clustering/ # Cluster transaction types
â”‚   â”‚   â”‚   â”œâ”€â”€ 02b_description_encoding/        # BERT encoding + clustering
â”‚   â”‚   â”‚   â””â”€â”€ 02_feature_engineering.py        # Main pipeline
â”‚   â”‚   â”œâ”€â”€ 03_fraud_relabeling/     # Step 3: Fraud matching and re-labeling
â”‚   â”‚   â”œâ”€â”€ 04_encoding/             # Step 4: Feature encoding
â”‚   â”‚   â”œâ”€â”€ 05_vulnerability_scanner/ # Security protection
â”‚   â”‚   â””â”€â”€ pipeline.ipynb           # Complete preprocessing pipeline
â”‚   â”‚
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ preprocessing/           # Model-specific preprocessing
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ config/                      # Configuration files
â”‚   â””â”€â”€ tokenize_dict.json       # Categorical encoding dictionary
â”‚
â”œâ”€â”€ .venv/                       # Virtual environment
â”œâ”€â”€ venv/                        # Alternative virtual environment
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ setup.py
```

## ğŸ”„ Data Processing Pipeline

The preprocessing pipeline consists of 4 sequential stages:

### Step 1: Data Cleaning (`01_data_cleaning`)
- Standardize CSV headers
- Fix comma and formatting issues
- Clean Amount field (remove $, convert to numeric)
- Fill missing values
- Rename files based on date range

**Data Flow**: `raw/` â†’ `cleaned/`

### Step 2: Feature Engineering (`02_feature_engineering`)
- Encode transaction descriptions using BERT-tiny
- Apply PCA dimensionality reduction
- Perform automatic clustering (MiniBatchKMeans)
- Add cluster_id column

**Data Flow**: `cleaned/` â†’ `clustered_out/`

### Step 3: Fraud Matching (`03_fraud_relabeling`)
- **Stage 1**: Reorganize transactions by Member ID
- **Stage 2**: Match fraud adjustments to original transactions
- Filter members with â‰¥10 transactions
- Categorize into matched/unmatched/no_fraud

**Data Flow**: `clustered_out/` â†’ `by_member/` â†’ `processed/[matched|unmatched|no_fraud]/`

### Step 4: Feature Encoding (`04_encoding`)
- Remove ID columns (Account ID, Member ID)
- Encode categorical features (Account Type, Action Type, etc.)
- Parse time features to decimal hours
- Convert date features
- Remove text columns

**Data Flow**: `processed/` â†’ `final/[matched|unmatched|no_fraud]/`

**Final Output**: `data/final/` contains model-ready datasets

## ğŸš€ Quick Start

1. **Clone the repository**

```bash
git clone <repository-url>
cd ClearShield
```

2. **Set up environment**

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
python setup.py            # Creates directories and installs dependencies
```

Or use Makefile:
```bash
make setup
```

3. **Run the preprocessing pipeline**

**Option A: Automated Script (Recommended)**
```bash
cd src/data_preprocess
python run_pipeline.py
```

Or using Makefile:
```bash
make run
```

Advanced usage:
```bash
python run_pipeline.py --help                    # Show all options
python run_pipeline.py --skip-cleaning           # Skip data cleaning
python run_pipeline.py --min-history 15          # Set minimum history to 15
```

**Option B: Jupyter Notebook (For exploration)**
- Open `src/data_preprocess/pipeline.ipynb`
- Execute cells sequentially to run the complete 4-stage pipeline

**Final datasets** will be in `data/final/[matched|unmatched|no_fraud]/`

4. **Train models**

- Navigate to `src/models/`
- Use datasets from `data/final/[matched|unmatched|no_fraud]/`
- Follow model-specific training instructions
